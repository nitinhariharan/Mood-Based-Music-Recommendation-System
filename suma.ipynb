{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "emotion_model = Sequential()\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "emotion_model.load_weights('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_data_of_face(x):\n",
    "    a=[]\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    img_path=x\n",
    "    img = cv2.imread('E:\\\\project\\\\user.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for (j,face) in enumerate(faces):\n",
    "            points = predictor(gray, face)\n",
    "\n",
    "            print('\\nface #',j+1)\n",
    "            l=[]\n",
    "            print('\\nface boundary coordinate\\n')\n",
    "            for i in range(0, 27):  # loop for displaying face boundary coordinate\n",
    "                curr_c = (points.part(i).x, points.part(i).y)\n",
    "            #print(curr_c)\n",
    "        #print('\\nnose coordinate\\n')\n",
    "            for i in range(27, 36):  # loop for displaying nose  coordinate\n",
    "                curr_c = (points.part(i).x, points.part(i).y)\n",
    "            #print(curr_c)\n",
    "        #print('\\nleft eye coordinate\\n')\n",
    "            for i in range(36, 42):  # loop for displaying left eye coordinate\n",
    "                curr_c = (points.part(i).x, points.part(i).y)\n",
    "            #print(curr_c)\n",
    "        #print('\\nright eye coordinate\\n')\n",
    "            for i in range(42, 48):  # loop for displaying right eye coordinate\n",
    "                curr_c = (points.part(i).x, points.part(i).y)\n",
    "            #print(curr_c)\n",
    "        #print('\\nlips coordiante\\n')\n",
    "            for i in range(48, 68):  # loop for displaying lips coordinate\n",
    "                curr_c = (points.part(i).x, points.part(i).y)\n",
    "            #print(curr_c)\n",
    "\n",
    "            for i in range(5, 12):                          #loop for storing jaw coordinates\n",
    "                curr_c=(points.part(i).x, points.part(i).y)\n",
    "                l.append(curr_c)\n",
    "\n",
    "            #cv2.line(img, curr_c, next_cordi, (0, 0, 0), 3)\n",
    "            for n in range(0, 68):                          #loop for detecting feature points on face\n",
    "                x = points.part(n).x\n",
    "                y = points.part(n).y\n",
    "            #cv2.circle(img, (x, y), 3, (0, 0, 255), 2)\n",
    "\n",
    "        #points = face_utils.shape_to_np(points)\n",
    "\n",
    "        # to  convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(face)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            img1=img[y:y+h,x:x+w]\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "            cropped_img = np.expand_dims(np.expand_dims(cv2.resize(img1, (48, 48)), -1), 0)\n",
    "            \n",
    "        #cv2.imwrite(\"user_me.jpg\",cropped_img)\n",
    "\n",
    "            a.append(int(np.argmax(emotion_model.predict(cropped_img))))\n",
    "            print(int(np.argmax(emotion_model.predict(cropped_img))))\n",
    "            print(a)\n",
    "            b = {0:\"Angry\",1:\"Disgusted\",2:\"Fearful\",3:\"Happy\",4:\"Neutral\",5:\"Sad\",6:\"Surprised\"}\n",
    "            for i in range(0,len(a)):\n",
    "                print(b[a[i]])\n",
    "                return b[a[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22516/1917095125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:\\\\project\\\\1\\\\user.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrgb_img2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mimg_encoding2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_img2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompare_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_encoding\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_encoding2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Result: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "import cv2\n",
    "img = cv2.imread('E:\\\\project\\\\1\\\\user.jpg')\n",
    "rgb_img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "result = face_recognition.compare_faces([img_encoding], img_encoding2)\n",
    "print(\"Result: \", result)\n",
    "given_image = face_recognition.load_image_file('E:\\\\project\\\\1\\\\user-black.jpg')\n",
    "face_locations = face_recognition.face_locations(given_image)\n",
    "\n",
    "number_of_faces = len(face_locations)\n",
    "print(\"We found {} face(s) in this image.\".format(number_of_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "face # 1\n",
      "\n",
      "face boundary coordinate\n",
      "\n",
      "6\n",
      "[6]\n",
      "Surprised\n",
      "Surprised\n"
     ]
    }
   ],
   "source": [
    "print(main_data_of_face('user.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "Tv = DeepFace.analyze(img_path = \"user.jpg\", \n",
    "        actions =  'emotion',enforce_detection=False\n",
    ")\n",
    "Tv=Tv[0]['emotion']\n",
    "Keymax = max(zip(Tv.values(), Tv.keys()))[1]\n",
    "print(Keymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2a7d5b852d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('test.db')\n",
    "\n",
    "print(\"Opened database successfully\")\n",
    "\n",
    "\n",
    "\n",
    "conn.execute('''CREATE TABLE suma\n",
    "         (ID INT AUTO_INCREMENT,\n",
    "         MOOD        CHAR(50),\n",
    "         LINK         REAL);''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x2a7d5b9c340>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('''insert into suma values(1,1,1)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=dOVvD5Kf6xA', 'sad']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='https://www.youtube.com/watch?v=dOVvD5Kf6xA|sad'\n",
    "text=text.split('|')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "  \n",
    "# creating function\n",
    "def scrape_info(url):\n",
    "      \n",
    "    # getting the request from url\n",
    "    r = requests.get(url)\n",
    "      \n",
    "    # converting the text\n",
    "    s = BeautifulSoup(r.text, \"html.parser\")\n",
    "      \n",
    "    # finding meta info for title\n",
    "    title = s.find(\"span\", class_=\"watch-title\").text.replace(\"\\n\", \"\")\n",
    "      \n",
    "    # finding meta info for views\n",
    "    views = s.find(\"div\", class_=\"watch-view-count\").text\n",
    "      \n",
    "    # finding meta info for likes\n",
    "    likes = s.find(\"span\", class_=\"like-button-renderer\").span.button.text\n",
    "      \n",
    "    # saving this data in dictionary\n",
    "    data = {'title':title, 'views':views, 'likes':likes}\n",
    "      \n",
    "    # returning the dictionary\n",
    "    return data\n",
    "  \n",
    "# main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15652/82415319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# calling the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# printing the dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15652/2379640605.py\u001b[0m in \u001b[0;36mscrape_info\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# finding meta info for title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"watch-title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# finding meta info for views\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "      \n",
    "    # URL of the video\n",
    "    url =\"https://www.youtube.com/watch?time_continue=17&v=2wEA8nuThj8\"\n",
    "      \n",
    "    # calling the function\n",
    "    data = scrape_info(url)\n",
    "      \n",
    "    # printing the dictionary\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Module\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "youtube = build('youtube','v3', developerKey=\"AIzaSyBTZN1W54ksvEl37jHwW4kdJ75vBh89vnA\") \n",
    "\n",
    "str='https://www.youtube.com/watch?v=tioS43maiHk'\n",
    "str=str.split('=')\n",
    "# retrieve youtube video results \n",
    "video_request=youtube.videos().list(\n",
    "  part='snippet,statistics',\n",
    "  id=str[1]\n",
    ")\n",
    "  \n",
    "video_response = video_request.execute()\n",
    "title = video_response['items'][0]['snippet']['title']\n",
    "likes = video_response['items'][0]['statistics']['likeCount']\n",
    "views = video_response['items'][0]['statistics']['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Home At Last'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
